{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # 'os' module provides a way to interact with the operating system and perform various tasks related to file and directory operations\n",
    "\n",
    "from collections import namedtuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass \n",
    "\n",
    "\"\"\"When you use the @dataclass decorator, Python automatically generates the following methods for you:\n",
    "\n",
    "__init__(): A constructor that initializes the attributes.\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True) \n",
    "\n",
    "# The @dataclass(frozen=True) decorator is a modification of the standard @dataclass decorator in Python's dataclasses module. \n",
    "# When you use @dataclass(frozen=True), it adds the \"frozen\" behavior to the data class, making its instances immutable. \n",
    "# This means that once you create an instance of a frozen data class, you cannot modify its attributes.\n",
    "\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL:str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplearningpractice.constants import * \n",
    "# Constants which are not varied is included in the constants folder and importing when required\n",
    "\n",
    "from deeplearningpractice.utils import read_yaml,create_directories \n",
    "# importing the read_yaml method from utils for reading the yaml file and storing in the specific variable.\n",
    "# importing the create_directories from utils for creating the directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath) # reading the config.yaml file with read_yaml method\n",
    "        self.params = read_yaml(params_filepath) # reading the params.yaml file with read_yaml method\n",
    "\n",
    "        create_directories([self.config.artifacts_root]) # creates artifacts folder\n",
    "\n",
    "    \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig: \n",
    "        # creating custom return type by using the -> DataIngestionConfig which is the class created in the 2nd cell.\n",
    "        \n",
    "        config = self.config.data_ingestion \n",
    "\n",
    "        \"\"\"After reading the config.yaml file with read_yaml method, data_ingestion parameters like \n",
    "           (root_dir: Path\n",
    "           source_URL:str\n",
    "           local_data_file: Path\n",
    "           unzip_dir: Path) \n",
    "           are taken and stored in config variable\"\"\"\n",
    "\n",
    "        create_directories([config.root_dir]) # creating the directory as data_ingestion file in the artifacts ==> root_dir: artifacts/data_ingestion\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_URL=config.source_URL,\n",
    "            local_data_file=config.local_data_file,\n",
    "            unzip_dir=config.unzip_dir \n",
    "        )\n",
    "\n",
    "        \"\"\" Now calling the data_ingestion parameter values like \n",
    "                    (root_dir: artifacts/data_ingestion\n",
    "                    source_URL: https://github.com/entbappy/Branching-tutorial/raw/master/cat-dog-data.zip\n",
    "                    local_data_file: artifacts/data_ingestion/data.zip\n",
    "                    unzip_dir: artifacts/data_ingestion) \n",
    "            using the config variable. Now using dot operator and calling the parameter values and storing on the parameter variables\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        return data_ingestion_config # returing the data_ingestion_config parameters which are used used furthur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "\n",
    "\"\"\"\n",
    "import urllib.request as request is used to import the request submodule from the urllib package in Python. The urllib package is a library \n",
    "for working with URLs and performing various network-related tasks, such as making HTTP requests, fetching web content, and more.\n",
    "\"\"\"\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\"\"\"\n",
    "from zipfile import ZipFile is used to import the ZipFile class from the zipfile module in Python. The zipfile module is part of Python's \n",
    "standard library and provides functionality for creating, reading, and manipulating ZIP archives.\n",
    "\n",
    "The ZipFile class in the zipfile module allows you to work with ZIP archives. You can use it to create new ZIP files, extract files from existing ZIP files, \n",
    "add files to existing ZIP files, and perform various operations on the contents of ZIP archives.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config # accessing the all configuration files for data ingestion like root_dir, source_URL, local_data_file, unzip_dir\n",
    "\n",
    "    \n",
    "    def download_file(self): # downloading the files\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            filename, headers = request.urlretrieve(\n",
    "                url = self.config.source_URL,\n",
    "                filename = self.config.local_data_file\n",
    "            )\n",
    "\n",
    "    \n",
    "    def _get_updated_list_of_files(self, list_of_files):\n",
    "        return [f for f in list_of_files if f.endswith(\".jpg\") and (\"Cat\" in f or \"Dog\" in f)] # this line will be changed based on different projects\n",
    "    \n",
    "\n",
    "    \n",
    "    def _preprocess(self, zf: ZipFile, f: str, working_dir: str): # if the size of the file is 0 it will remove\n",
    "        target_filepath = os.path.join(working_dir, f)\n",
    "        if not os.path.exists(target_filepath):\n",
    "            zf.extract(f, working_dir)\n",
    "        \n",
    "        if os.path.getsize(target_filepath) == 0:\n",
    "            os.remove(target_filepath)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    def unzip_and_clean(self):\n",
    "        with ZipFile(file=self.config.local_data_file, mode=\"r\") as zf:\n",
    "            list_of_files = zf.namelist()\n",
    "            updated_list_of_files = self._get_updated_list_of_files(list_of_files)\n",
    "            for f in updated_list_of_files:\n",
    "                self._preprocess(zf, f, self.config.unzip_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager() # calling ConfigurationManager class and storing in the config variable as an object.\n",
    "    data_ingestion_config = config.get_data_ingestion_config() # Now by using the object, get_data_ingestion_config method is called and stored in data_ingestion_config as new object\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config) # Now calling the DataIngestion class with all config.yaml parameter values and storing in new data_ingestion object\n",
    "    data_ingestion.download_file() # Using the data_ingestion object calling the download_file method.\n",
    "    data_ingestion.unzip_and_clean() # Using the data_ingestion object calling the unzip_and_clean method.\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now update the above code in python files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update in config.yaml file\n",
    "\n",
    "artifacts_root: artifacts\n",
    "\n",
    "\n",
    "data_ingestion:\n",
    "root_dir: artifacts/data_ingestion\n",
    "source_URL: https://github.com/entbappy/Branching-tutorial/raw/master/cat-dog-data.zip\n",
    "local_data_file: artifacts/data_ingestion/data.zip\n",
    "unzip_dir: artifacts/data_ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update In entity/config_entity.py\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update In config/configuration.py\n",
    "\n",
    "\n",
    "from cnnClassifier.utils import read_yaml, create_directories\n",
    "from cnnClassifier.constants import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "from cnnClassifier.entity import DataIngestionConfig\n",
    "                                  \n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_URL=config.source_URL,\n",
    "            local_data_file=config.local_data_file,\n",
    "            unzip_dir=config.unzip_dir \n",
    "        )\n",
    "\n",
    "        return data_ingestion_config\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In entity/__init__.py file\n",
    "\n",
    "\n",
    "from cnnClassifier.entity.config_entity import DataIngestionConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In config/__init__.py file\n",
    "\n",
    "\n",
    "from cnnClassifier.config.configuration import ConfigurationManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# components/data_ingestion.py\n",
    "\n",
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from cnnClassifier.entity import DataIngestionConfig\n",
    "from cnnClassifier import logger\n",
    "from cnnClassifier.utils import get_size\n",
    "\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def download_file(self):\n",
    "        logger.info(\"Trying to download file...\")\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            logger.info(\"Download started...\")\n",
    "            filename, headers = request.urlretrieve(\n",
    "                url=self.config.source_URL,\n",
    "                filename=self.config.local_data_file\n",
    "            )\n",
    "            logger.info(f\"{filename} download! with following info: \\n{headers}\")\n",
    "        else:\n",
    "            logger.info(f\"File already exists of size: {get_size(Path(self.config.local_data_file))}\")        \n",
    "\n",
    "    def _get_updated_list_of_files(self, list_of_files):\n",
    "        return [f for f in list_of_files if f.endswith(\".jpg\") and (\"Cat\" in f or \"Dog\" in f)]\n",
    "\n",
    "    def _preprocess(self, zf: ZipFile, f: str, working_dir: str):\n",
    "        target_filepath = os.path.join(working_dir, f)\n",
    "        if not os.path.exists(target_filepath):\n",
    "            zf.extract(f, working_dir)\n",
    "        \n",
    "        if os.path.getsize(target_filepath) == 0:\n",
    "            logger.info(f\"removing file:{target_filepath} of size: {get_size(Path(target_filepath))}\")\n",
    "            os.remove(target_filepath)\n",
    "\n",
    "    def unzip_and_clean(self):\n",
    "        logger.info(f\"unzipping file and removing unawanted files\")\n",
    "        with ZipFile(file=self.config.local_data_file, mode=\"r\") as zf:\n",
    "            list_of_files = zf.namelist()\n",
    "            updated_list_of_files = self._get_updated_list_of_files(list_of_files)\n",
    "            for f in tqdm(updated_list_of_files):\n",
    "                self._preprocess(zf, f, self.config.unzip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline/stage_01_data_ingestion.py\n",
    "\n",
    "\n",
    "from cnnClassifier.config import ConfigurationManager\n",
    "from cnnClassifier.components import DataIngestion\n",
    "from cnnClassifier import logger\n",
    "\n",
    "class DataIngestionTrainingPipeline:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def main(self):\n",
    "        config = ConfigurationManager()\n",
    "        data_ingestion_config = config.get_data_ingestion_config()\n",
    "        data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "        data_ingestion.download_file()\n",
    "        data_ingestion.unzip_and_clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In components/__init__.py\n",
    "\n",
    "from cnnClassifier.components.data_ingestion import DataIngestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In main.py file\n",
    "\n",
    "from cnnClassifier.pipeline.stage_01_data_ingestion import DataIngestionTrainingPipeline\n",
    "\n",
    "STAGE_NAME = \"Data Ingestion stage\"\n",
    "try:\n",
    "   logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\") \n",
    "   data_ingestion = DataIngestionTrainingPipeline()\n",
    "   data_ingestion.main()\n",
    "   logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\\n\\nx==========x\")\n",
    "except Exception as e:\n",
    "        logger.exception(e)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnncls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
